# redis QA
## 数据结构与对象
### Redis的整体存储结构
- redis有五个对象: string、list、hash、set与sort set;
- string有三种底层实现: long int、raw、embstr;
- list有两种实现方式: 压缩列表ziplist、双端链表linkedlist;
- hash有两种底层实现: 压缩列表ziplist、hashtable;
- set有两种底层实现: 整数集合intset、hashtable;
- sort set有两种底层实现: 压缩列表ziplist、跳跃表skiplist;

### redis hash的实现; rehash过程讲一下
- hash有两种底层实现,一个是压缩列表ziplist、一个是hashtable;
- ziplist在hash里面是一个key一个value按照添加顺序排列的;获取len是ziplist的结点数量除以2;
- 当ziplist存在某个key或者value超过64字节,或者k-v数超过512个,ziplist就会转换成hashtable;
- hashtable实现是一个指针数组,数组里单个node保存了k-v值;通过key计算对应的hash值再加上ht的masksize计算出索引值,可以得到这个key在数组里的位置;
- redis的ht是通过拉链法来解决hash冲突的,如果计算出key在数组里的位置已经有数据了,会在这个node里面找到一个next指针,往后遍历直到找到next指针为null的节点,将新数据加到next节点后,组成一个类似链表的结构;
- rehash:当ht保存的kv数量太多或者太少时,需要进行扩容/缩容的操作; 在hashtable里面会的数组是一个二维数组,数组0的位置保存了hash表的数据,1的位置会根据当前数据大小建立一个新的hash表; 然后在每次进行kv操作时会将新数据与更新的数据写到`array[1]`位置的hash表里面;`array[0]`所有数据都转到`array[1]`里面,再将`array[1]`替换掉`array[0]`;


### Redis有哪些结构时间复杂度较高
- 链表,查找更新删除都是O(N), 但是链表一般都是使用pop与push操作,都是对头尾结点进行操作,复杂度O(1);

- 压缩表: 查找更新删除都是平均O(N),更新删除可能是`O(N^2)`(触发连锁更新);压缩表主要用于list、hash与sort set三个类型小数据量时, 使用这个结构的目的是节约空间,因为数据量小,所以O(N)与O(1)或者O(logN)的结构并没有太大量级上的差距;


### redis的zset的使用场景、实现方式;ziplist的限制;跳表数据结构、跳表的时间复杂度
- zset通常用于排序,例如排行榜;另外业务里面经常将score设置为时间戳;
- zset的实现方式是ziplist和skiplist;
- ziplist的限制是,因为是连续一段内存保存数据,查找的复杂度是O(N),如果更新与删除触发了连锁更新,需要进行N次重新分配操作,每次分配复杂度都在O(N),所以复杂度是`O(N^2)`;
- skiplist是对linkedlist的一种优化方式, 将前进指针改成跳跃指针数组, 通过投硬币的方式来决定数组的长度(配置文件限制了最长值,32层或者64层); 指针数组指向下一个有相同高度结点; 因为skiplist是根据score顺序排列的, 这样通过类似`抄近路`的方式减少了索引的复杂度, 理论上时间复杂度近似于二分查找树`O(logN)`;


### 跳跃表，为什么使用跳跃表而不使用红黑树
- 跳表对比红黑树, 优点在于维护平衡的代价很小: 红黑树需要通过左旋右旋和变色来维护二叉树的平衡, 而跳表只需要对前后结点的指针进行操作,然后维护一下索引数组就行了;
- 跳表的范围查询速度极快,只需要找到最小值,对第一层链表进行遍历就行了;而红黑树需要在最小值结点处开始中序遍历查找不超过最大值的节点; 
- 跳跃表对比红黑树的缺点在于索引数组需要额外的内存空间;


## 实现
### redis的内存分配方式、哪个分配器? 内存碎片是怎样发生的，怎样解决。
- redis内存分配器默认是jemalloc: 一共有small、large、huge三种类型的内存块, 每种内存快内部又划分了若干小内存单元;
- 例如一个对象为5kb,分配器有4kb块和8kb块,那么分配器会给他分8kb的块,多余的3kb就变成了内存碎片;在进行频繁更新删除操作时会导致碎片率上升;
- 4.0之前通过重启来解决,4.0之后通过`memory purge`来整理内存碎片;

### Redis连接时的connect与pconnect的区别
pconnect是php里面实现的一个redis连接池, php-fpm会保存这次redis连接直到下次使用或者超时;防止频繁建立redis连接;


### redis的删除策略。定时 定期 惰性 lru
- 定期+惰性; 
- 定期取出随机key抽查过期时间;
- 惰性: 当key读取到时会检查过期时间;
- LRU: `redisObject.lru`字段记录了最后操作时间, 当redis超过设置的内存时会优先释放lru最早的那些对象;


### redis为什么是单线程? 讲epoll底层和两种模式; 
- 因为是纯内存操作,速度足够快;
- 单线程不需要进行上下文切换,减少开销;不需要多进程切换导致消耗cpu,不用考虑锁的问题;
- 使用epoll+简单的事件框架, 将读、写、关闭、连接都转换成了event,然后利用epoll多路复用的特性,不在io上浪费事件;


### 怎么解决redis在并发下商品超卖的问题？
- 通过setnx实现的分布式锁进行库存判断与预扣库存; 
- 下单等操作投递到MQ,后面起几个消费者去拉MQ(注意是拉,如果结构是MQ主动推给消费者,可能会瞬时大流量推挂)


### 为什么在业务里用 Redis, redis有什么优点?
- 短平快: 单线程-并发安全；异步io、纯内存性能高；
- 用的比较多,有各种成熟的高可用/集群方案,踩坑成本低;


### redis的持久化机制，为啥不能用redis做专门的持久化数据库存储？
- redis通过RDB+AOF进行持久化;
- RDB: redis开启子进程, 将数据直接备份成rdb二进制文件,备份周期比较长;
- AOF: 将执行命令写入aof缓冲区,再从缓冲区刷到aof文件里面;
- redis主要是拿来做缓存,应付读多写少的环境,数据保存在内存里,随时可能被LRU, 因此不能做持久化存储; 

RDB优点:
- 适合大规模的数据恢复，如果业务对数据完整性和一致性要求不高，RDB 的启动速度更快，是很好的选择。
- RDB 文件简洁，它保存了某个时间点的 Redis 数据集，适合用于做备份。你可以设定一个时间点对 RDB 文件进行归档，如果 1s 间隔保存一次快照，这样就能在需要的时候很轻易地把数据恢复到不同的版本。
- 考虑到磁盘硬件故障问题，RDB 文件很适合用于灾备，因为单文件可以很方便地传输到另外的数据中心。
- RDB 的性能很好，需要进行持久化时，主进程会 fork 一个子进程出来，然后把持久化的工作交给子进程，自己不会有相关的 I/O 操作。

缺点:
- 数据的完整性和一致性不高，因为 SAVE 命令执行是有时间间隔的，比如 5min 备份一次，RDB 可能在最后一次备份时宕机，这 5min 的时间窗数据可能丢失。
- 备份时占用内存，因为 Redis 在备份时会独立创建一个子进程，将数据写入到一个临时文件（此时内存中的数据是原来的两倍），最后再将临时文件替换之前的备份文件。所以 Redis 的持久化和数据的恢复要选择在夜深人静的时候执行是比较合理的。

AOF:
- 优点: AOF策略最大限度地保证数据不丢失，数据的完整性和一致性更高。
- 缺点: AOF 备份产生的 appendonly.aof 文件较大，数据恢复的时候，也会比较慢，Redis 针对 AOF 文件大的问题，提供重写的瘦身机制。(命令合并)



## 运维/分布式
### redis怎么达到分布式一致性
- 遵循gossip协议发送meet、ping、pong、fail等消息,同步各个结点的信息;
- 哨兵模式使用raft协议的头领选举算法, sentinel发现master进入客观下线状态,会向其他sentinel发送消息推举自己为leader; 当某个sentinel获得超过半数票时,会将自身设置成leader,并将信息同步给其他sentinel;
- 每个节点都有一个配置纪元(计数器),收到相关选举消息时会对比配置纪元,确定是当前配置纪元的选举才会参与; 每次投票完配置纪元+1;

### redis分布式，如何减少同步延迟
要先确定同步延迟产生的原因: 
- redis瓶颈通常是网络IO: 首先看是不是网速的原因, 保证集群在同一个交换机下面, 带宽足够大;
- redis一些参数配置是否不正确;
- 程序最好能在设计时容忍一部分延迟(比如订单缓存,可以提示用户订单同步有1-2分钟延迟);也可以写程序用来监控主从的复制偏移量,暂时禁用掉延迟过大的从库;
- 加大服务器配置,redis的设备瓶颈通常是内存;
- 减少同步的从节点数量;

### redis容灾，备份，扩容
- 容灾: sentinel
- 备份: RDB, AOF
- 扩容: redis-trib工具 横向增加新节点;(同构平分slots,异构按性能分slots)


### redis cluster有没有了解过，怎么做到高可用的？
cluster的高可用是通过slave来做的:
- slave检测到master变成fail, 会向其他有投票权(分配了slots)的node发送消息要求给自己投票;
- 其他node在当前配置纪元收到的第一条FAILOVER_REQUEST消息, 会给slave 回复ACK消息;
- slave统计得票,如果超过半数node给自己投票,则slave宣布自己成为master,同时执行`slaveof no one`,并广播自己的信息给其他节点;


### 分布式锁有哪些主流实现方式?redis和 zk 锁有什么区别?
- redis的setnx, 需要注意几点:

    1. 过期时间和set需要是原子操作,使用`set <key> <value> EX <timeout> NX`同时设置;或者使用lua脚本;
    2. 解锁操作,需要判断该锁是否是该进程加的,再执行del操作;否则会出现误删其他进程锁的情况;但这又不是一个原子操作;同样建议使用脚本完成;
    3. 过期时间的长短是一个问题,程序执行时间过长,程序应该向redis延长过期时间;(但如果程序卡死就无法实现, 恢复之后锁已经超时被别人加上去了)
    4. 市面上有成熟的redisson;

或者使用zk:
- 获取zk的分布式锁,zk会创建一个znode;另外一个机器也尝试去创建那个 znode，结果发现自己创建不了，因为被别人创建了，那只能等待;
- 使用 ZooKeeper 的顺序节点特性，假如我们在/lock/目录下创建3个节点，ZK集群会按照发起创建的顺序来创建节点，节点分别为/lock/0000000001、/lock/0000000002、/lock/0000000003，最后一位数是依次递增的，节点名由zk来完成;
- ZK中还有一种名为临时节点的节点，临时节点由某个客户端创建，当客户端与ZK集群断开连接，则该节点自动被删除。`EPHEMERAL_SEQUENTIAL`为临时顺序节点。

1. 客户端调用create()方法创建名为“/dlm-locks/lockname/lock-”的临时顺序节点。
2. 客户端调用getChildren(“lockname”)方法来获取所有已经创建的子节点。
3. 客户端获取到所有子节点path之后，如果发现自己在步骤1中创建的节点是所有节点中序号最小的，就是看自己创建的序列号是否排第一，如果是第一，那么就认为这个客户端获得了锁，在它前面没有别的客户端拿到锁。
4. 如果创建的节点不是所有节点中需要最小的，那么则监视比自己创建节点的序列号小的最大的节点，进入等待。直到下次监视的子节点变更的时候，再进行子节点的获取，判断是否获取锁。

区别: // todo


### 介绍下 Fescar/了解 CAP 吗?redis里的 CAP 是怎样的?
- CAP是分布式系统能够满足的三种特性: Consistency一致性、Availability可用性、Partition tolerance分区容错性;
- 一致性表示所有节点在同一时间的数据完全一致,
- 可用性指服务一直可用，而且是正常响应时间;
- 容错性指在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务。
- 只能满足其中两点,例如出现网络故障,主从仍然可以访问,满足P;但是从库数据偏移;如果从库允许操作,就不满足一致性,如果从库不允许操作,就不满足可用性;
- 根据业务不同有不同的侧重,例如对用户服务通常牺牲一致性,满足AP,保证服务正常运行,只是数据可能有延迟;对库存或者交易订单通常牺牲可用性,必须保证数据一致.

- redis单节点满足CA: 因为不涉及网络分区;
- redis哨兵模式满足CA: 哨兵保证了可用性,如果slave只是复制,则满足强一致性;
- cluster满足AP,因为cluster是通过分片来实现的,不存在数据一致的可能;
    

### 经典三连: 雪崩，穿透，击穿
- 雪崩就是指缓存中大批量热点数据同时过期, 大流量涌入数据库;

    解决办法：
    - 将缓存失效时间分散开，比如每个key的过期时间是随机，防止同一时间大量数据过期现象发生，这样不会出现同一时间全部请求都落在数据库层，如果缓存数据库是分布式部署，将热点数据均匀分布在不同Redis和数据库中，有效分担压力。
    - (如果准许)让Redis数据永不过期 / 或者可以加超长过期时间,每次请求重设过期时间。比如中奖名单用户，每期用户开奖后，名单不可能会变了，无需更新。

- 穿透是指数据在redis与db都不存在, 大流量请求导致db压力极大;

    解决办法:
    - 分布式布隆过滤器：布隆是BloomFilter音译过来的，Redis 自身支持BloomFilter。
    - 返回空值：遇到数据库和Redis都查询不到的值，在Redis里set一个null value，过期时间很短，目的在于同一个key再次请求时直接返回null，避免穿透。

- 击穿和穿透概念类似，一般是指一个key被穿透，这个key是热点key，同一个key会被有成千上万次请求，比如微博热点排行榜，key是小时时间戳，value是个list的榜单。每个小时产生一个key，这个key会有百万QPS，如果这个key失效了，就像保险丝熔断，百万QPS直接压垮数据库。

    解决办法: 未命中缓存,先加分布式锁,再读db设置缓存,释放锁;

举例子: app轮询用户的消息列表, 使用了布隆过滤器，过滤没有未读消息的用户;

BloomFilter检索一个元素是否在一个集合中有一定的错误率（很低），但不会漏判。
- 如果判断一个key不在集合中，那一定不在。
- 如果判断一个key存在，那不一定真的在。
- 本质上布隆过滤器是一种比较巧妙的概率型数据结构（probabilistic data structure），特点是高效地插入和查询，可以用来告诉你 “某样东西一定不存在或者可能存在”。
- 相比于传统的 List、Set、Map 等数据结构，它更高效、占用空间更少，但是缺点是其返回的结果是概率性的，而不是确切的。

原理是: 利用一个足够好的Hash函数将一个字符串映射到二进制位数组中的某一位，这样不管字符串如何长，都只有一位，因此存储空间就极大的提升了。但是不管hash函数如何高效，总是会存在Hash冲突，尤其是数据量变大的时候，而BloomFilter是利用多个不同的Hash函数来解决“冲突”，即一次采用多个Hash函数把数据映射到不同的位上，降低了冲突概率。BloomFilter有个缺点是不能删除数据，因为删除数据可能会影响到其它数据，有一些增强算法可以实现改功能，但代价比较大，不建议使用。

BloomFilter十分适合海量数据去重、过滤，尤其是当检测的字符串比较大时，极大地节省内存和存储空间，同时查询效率也十分高效。如果只是在内存使用，直接使用guava包的api即可；如果要做到分布式，结合Redis可以高效实现分布式的过滤效果。


### 热点key大Value解决方案?
> 相同的key会请求到同一台数据分片上，导致该分片负载较高成为瓶颈问题，导致雪崩等一系列问题。

问题: 
- 高访问量的Key，一个key访问的QPS超过1000就要高度关注了，比如热门商品，热门话题等。
- 大Value，有些key访问QPS虽然不高，但是由于value很大，造成网卡负载较大，网卡流量被打满，单台机器可能出现千兆 / 秒，IO 故障。
- 热点 Key + 大 Value 同时存在，服务器直接挂。

导致:
- 数据倾斜问题：大 Value 会导致集群不同节点数据分布不均匀，造成数据倾斜问题，大量读写比例非常高的请求都会落到同一个 redis server 上，该 redis 的负载就会严重升高，容易打挂。
- QPS 倾斜：分片上的 QPS 不均。
- 大 Value 会导致 Redis 服务器缓冲区不足，造成 get 超时。
- 由于 Value 过大，导致机房网卡流量不足。
- Redis 缓存失效导致数据库层被击穿的连锁反应。

如何发现问题:
- 提前获知: 根据业务，人肉统计 or 系统统计可能会成为热点的数据，如，促销活动商品，热门话题，节假日话题，纪念日活动等;
- Redis客户端通过计数的方式统计key的请求次数; 代码入侵性较强;
- 代理层统计: 多做一层代理,统一cache查询入口,做收集上报; 这个成本比较高,需要自己开发;

- 服务端收集: 监控集群QPS, 对高QPS的节点使用`monitor`来分析热点key;(monitor会打印所有的命令) 在高并发条件下，会存在内存暴涨和 Redis 性能的隐患，所以此种方法适合在短时间内使用;

- redis4.0有基于LFU的热点key发现机制;

热点key解决办法:
- key拆分: 二级结构如hash,可以进行拆分;
- 迁移热点key: 热点key单独跑个节点;
- 限流, 对于写命令我们可以单独针对这个热点key来限流;
- 增加本地缓存: 对于数据一致性不是那么高的业务，可以将热点 key 缓存到业务机器的本地缓存中.但是当数据更新时，可能会造成业务和 Redis 数据不一致。

大value解决方案:

根据业务总结出value的大小:
1. 大：string类型 value > 10K，set、list、hash、zset 等集合数据类型中的元素个数 > 1000。
2. 超大：string类型 value > 100K，set、list、hash、zset 等集合数据类型中的元素个数 > 10000。

由于 Redis 是单线程运行的，如果一次操作的 value 很大会对整个 redis 的响应时间造成负面影响，所以，业务上能拆则拆，下面举几个典型的分拆方案：
1. 一个较大的kv拆分成几个kv，将操作压力平摊到多个redis实例中，降低对单个redis的IO影响;
2. 将分拆后的几个kv存储在一个hash中，每个field代表一个具体的属性，使用hget,hmget来获取部分的value，使用hset，hmset来更新部分属性。
3. hash、set、zset、list 中存储过多的元素: 类似于场景一种的第一个做法，可以将这些元素分拆。

4. 固定一个桶的数量，比如10000，每次存取的时候，先在本地计算field的hash值，对10000取模，确定该field落在哪个key上，核心思想就是将value打散，每次只 get 你需要的;
    ```
    newHashKey = hashKey + (hash(field) % 10000); 
    hset(newHashKey, field, value); 
    hget(newHashKey, field)
    ```

