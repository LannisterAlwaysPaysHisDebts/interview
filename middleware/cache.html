<!DOCTYPE html>
<html>
<head>
<title>cache.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h2 id="%E7%BC%93%E5%AD%98">缓存</h2>
<h3 id="%E7%BC%93%E5%AD%98%E7%9A%84%E6%B7%98%E6%B1%B0%E7%AE%97%E6%B3%95">缓存的淘汰算法?</h3>
<p>FIFO（First In First Out）： 先进先出算法，即先放入缓存的先被移除。
LRU（Least Recently Used）： 最近最少使用算法，使用时间距离现在最久的那个被移除。
LFU（Least Frequently Used）： 最不常用算法，一定时间段内使用次数（频率）最少的那个被移除。</p>
<h3 id="%E7%BC%93%E5%AD%98%E6%9B%B4%E6%96%B0%E7%9A%84%E6%A8%A1%E5%BC%8F%E4%BB%A5%E5%8F%8A%E4%BC%9A%E5%87%BA%E7%8E%B0%E7%9A%84%E9%97%AE%E9%A2%98%E5%92%8C%E5%BA%94%E5%AF%B9%E6%80%9D%E8%B7%AF">缓存更新的模式，以及会出现的问题和应对思路？</h3>
<ol>
<li>读: 命中缓存,未命中则读数据库,再写入缓存;(同时缓存记失效时间,防止没有更新操作时导致一直读到脏数据;)</li>
<li>写: 写数据库,再删除/更新缓存；（很多业务情况下是直接删缓存）</li>
<li>读的时候即使数据不存在，也要写一个短时间的缓存防止穿库。问题在于如果先来一波大量的null key，在nullkey过期时又来一大波用户，可能造成雪崩效应;解决办法是布隆过滤器;</li>
<li>第二步的问题: 如果缓存刚好失效,A读库拿到旧值, B更新同时删除缓存,A再写入缓存,这样就一直是脏数据库了; 但是这个问题出现概率很小,因为读库写缓存速度很快,不可能写做完了读还没做完;而且缓存设置了失效时间,过几分钟又回拉新的数据出来;</li>
<li>数据库和缓存双写一致性问题：先更新数据库再更新缓存，若更新完数据库了，还没有更新缓存，此时有请求过来了，访问到了缓存中的数据，怎么办？ 延时双删策略：先删缓存、再更新数据库、等待很短时间，再删除缓存。但延时双删并不是一个很好的策略，在更新完数据库等待的这段时间内，仍然会读到旧数据。能保持百分百一致性的方法就是加缓存了。</li>
</ol>
<h3 id="%E6%88%91%E4%BB%AC%E7%8E%B0%E5%9C%A8%E8%A6%81%E5%81%9A%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%98%AF%E7%99%BE%E4%B8%87qps%E7%BA%A7%E5%88%AB%E5%8D%B3%E4%BD%BF%E4%BD%BF%E7%94%A8%E4%BA%86redis%E8%BF%98%E6%98%AF%E4%B8%8D%E5%A4%9F%E5%BF%AB%E4%B8%8D%E5%A4%9F%E5%8F%AF%E9%9D%A0%E6%9C%89%E6%B2%A1%E6%9C%89%E5%88%AB%E7%9A%84%E5%8A%9E%E6%B3%95%E8%AE%A9%E7%B3%BB%E7%BB%9F%E6%9B%B4%E5%BF%AB%E6%9B%B4%E5%8F%AF%E9%9D%A0">我们现在要做的系统是百万QPS级别，即使使用了Redis，还是不够快，不够可靠，有没有别的办法让系统更快更可靠？</h3>
<blockquote>
<p>see https://www.imooc.com/read/63/article/1398
本地缓存</p>
</blockquote>
<ul>
<li>优先请求一级本地缓存，命中数据后直接返回;</li>
<li>如果本地缓存命中失败，请求二级缓存Redis，命中后直接返回;</li>
<li>如果Redis命中也失败了，再查mysql;</li>
</ul>
<p>常用本地缓存框架：</p>
<ul>
<li>Google Guava;</li>
<li>Ehcache;</li>
<li>语言自带的map;</li>
</ul>
<p>问题: 基本每一个服务都做集群的，每次请求相同的数据不一定请求到同一台服务器的，那本地缓存命中的几率是不是不太高了?</p>
<h3 id="%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E6%9C%89%E5%93%AA%E4%BA%9B%E4%B8%BB%E6%B5%81%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8Fredis%E5%92%8C-zk-%E9%94%81%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB">分布式锁有哪些主流实现方式?redis和 zk 锁有什么区别?</h3>
<ul>
<li>redis的setnx, 需要注意几点:
<ol>
<li>过期时间和set需要是原子操作,使用<code>set &lt;key&gt; &lt;value&gt; EX &lt;timeout&gt; NX</code>同时设置;或者使用lua脚本;</li>
<li>解锁操作,需要判断该锁是否是该进程加的,再执行del操作;否则会出现误删其他进程锁的情况;但这又不是一个原子操作;同样建议使用脚本完成;</li>
<li>过期时间的长短是一个问题,程序执行时间过长,程序应该向redis延长过期时间;(但如果程序卡死就无法实现, 恢复之后锁已经超时被别人加上去了)</li>
<li>市面上有成熟的redisson;</li>
</ol>
</li>
</ul>
<p>或者使用zk:</p>
<ul>
<li>获取zk的分布式锁,zk会创建一个znode;另外一个机器也尝试去创建那个znode，结果发现自己创建不了，因为被别人创建了，那只能等待;</li>
<li>使用ZooKeeper的顺序节点特性，假如我们在/lock/目录下创建3个节点，ZK集群会按照发起创建的顺序来创建节点，节点分别为/lock/0000000001、/lock/0000000002、/lock/0000000003，最后一位数是依次递增的，节点名由zk来完成;</li>
<li>ZK中还有一种名为临时节点的节点，临时节点由某个客户端创建，当客户端与ZK集群断开连接，则该节点自动被删除。<code>EPHEMERAL_SEQUENTIAL</code>为临时顺序节点。</li>
</ul>
<ol>
<li>客户端调用create()方法创建名为“/dlm-locks/lockname/lock-”的临时顺序节点。</li>
<li>客户端调用getChildren(“lockname”)方法来获取所有已经创建的子节点。</li>
<li>客户端获取到所有子节点path之后，如果发现自己在步骤1中创建的节点是所有节点中序号最小的，就是看自己创建的序列号是否排第一，如果是第一，那么就认为这个客户端获得了锁，在它前面没有别的客户端拿到锁。</li>
<li>如果创建的节点不是所有节点中需要最小的，那么则监视比自己创建节点的序列号小的最大的节点，进入等待。直到下次监视的子节点变更的时候，再进行子节点的获取，判断是否获取锁。</li>
</ol>
<h3 id="%E4%BB%8B%E7%BB%8D%E4%B8%8B-fescar%E4%BA%86%E8%A7%A3-cap-%E5%90%97redis%E9%87%8C%E7%9A%84-cap-%E6%98%AF%E6%80%8E%E6%A0%B7%E7%9A%84">介绍下 Fescar/了解 CAP 吗?redis里的 CAP 是怎样的?</h3>
<ul>
<li>
<p>CAP是分布式系统能够满足的三种特性: Consistency一致性、Availability可用性、Partition tolerance分区容错性;</p>
</li>
<li>
<p>一致性表示所有节点在同一时间的数据完全一致,</p>
</li>
<li>
<p>可用性指服务一直可用，而且是正常响应时间;</p>
</li>
<li>
<p>容错性指在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务。</p>
</li>
<li>
<p>只能满足其中两点,例如出现网络故障,主从仍然可以访问,满足P;但是从库数据偏移;如果从库允许操作,就不满足一致性,如果从库不允许操作,就不满足可用性;</p>
</li>
<li>
<p>根据业务不同有不同的侧重,例如对用户服务通常牺牲一致性,满足AP,保证服务正常运行,只是数据可能有延迟;对库存或者交易订单通常牺牲可用性,必须保证数据一致.</p>
</li>
<li>
<p>redis单节点满足CA: 因为不涉及网络分区;</p>
</li>
<li>
<p>redis哨兵模式满足CA: 哨兵保证了可用性,如果slave只是复制,则满足强一致性;</p>
</li>
<li>
<p>cluster满足AP,因为cluster是通过分片来实现的,不存在数据一致的可能;</p>
</li>
</ul>
<h3 id="%E7%BB%8F%E5%85%B8%E4%B8%89%E8%BF%9E-%E9%9B%AA%E5%B4%A9%E7%A9%BF%E9%80%8F%E5%87%BB%E7%A9%BF">经典三连: 雪崩，穿透，击穿</h3>
<ul>
<li>
<p>雪崩就是指缓存中大批量热点数据同时过期, 大流量涌入数据库;</p>
<p>解决办法：</p>
<ul>
<li>将缓存失效时间分散开，比如每个key的过期时间是随机，防止同一时间大量数据过期现象发生，这样不会出现同一时间全部请求都落在数据库层，如果缓存数据库是分布式部署，将热点数据均匀分布在不同Redis和数据库中，有效分担压力。</li>
<li>(如果准许)让Redis数据永不过期 / 或者可以加超长过期时间,每次请求重设过期时间。比如中奖名单用户，每期用户开奖后，名单不可能会变了，无需更新。</li>
</ul>
</li>
<li>
<p>穿透是指数据在redis与db都不存在, 大流量请求导致db压力极大;</p>
<p>解决办法:</p>
<ul>
<li>分布式布隆过滤器(bf BloomFilter)：Redis自身支持BloomFilter。</li>
<li>遇到数据库和Redis都查询不到的值，在Redis里set一个null value，过期时间很短，目的在于同一个key再次请求时直接返回null，避免穿透。</li>
</ul>
</li>
<li>
<p>击穿和穿透概念类似，一般是指一个key被穿透，这个key是热点key，同一个key会被有成千上万次请求，比如微博热点排行榜，key是小时时间戳，value是个list的榜单。每个小时产生一个key，这个key会有百万QPS，如果这个key失效了，就像保险丝熔断，百万QPS直接压垮数据库。</p>
<p>解决办法: 未命中缓存,先加分布式锁,再读db设置缓存,释放锁;</p>
</li>
</ul>
<h3 id="%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8">布隆过滤器？</h3>
<ul>
<li>在查业务缓存前设置一个bitmap，对于缓存key，通过若干hash函数，可以将其映射到bitmap的不同位置；</li>
<li>特点是如果某个key在bf里不存在那一定不存在；bf里存在则可能存在。</li>
<li>缺点是不能删除；而且在大数据量下bitmap里为1的数据越来越多，结果误判率越来越高，最后只能重建。</li>
<li>而且经过多个不同 Hash 函数后，得到的数组下标在内存中的跨度可能会非常的大，导致cpu缓存命中率降低。</li>
<li>并且可能出现大value的情况，需要切分。</li>
</ul>
<blockquote>
<p><a href="https://www.jasondavies.com/bloomfilter/">这里</a>有bf的动画演示，可以玩一玩</p>
</blockquote>
<p>拆分的形式方法多种多样，但是本质是不要将 Hash(Key) 之后的请求分散在多个节点的多个小 bitmap 上，而是应该拆分成多个小 bitmap 之后，对一个 Key 的所有哈希函数都落在这一个小 bitmap 上。</p>
<p>典型应用：1. 防止数据库穿库；2. 判断用户是否有阅读记录；3. 解决缓存击穿；4. web拦截器，相同请求拦截；</p>
<h3 id="%E5%B8%83%E8%B0%B7%E9%B8%9F%E8%BF%87%E6%BB%A4%E5%99%A8">布谷鸟过滤器</h3>
<p>原理是准备两个hash表，两个hash函数。对于每个key都计算出在这两个hash表里的位置。</p>
<ul>
<li>有空位，则占位；</li>
<li>没有空位，随机踢掉一个元素；</li>
<li>被踢掉的元素去找他另一个表的位置，如果有元素，继续踢掉；</li>
<li>又被踢掉的元素又去找另一个表的位置，一层一层套娃踢，直到有元素在另一个表里面有空位不用踢了，整个流程结束(数据量极大时需要设置套娃上限，防止无限循环)</li>
</ul>
<blockquote>
<p><a href="http://www.lkozma.net/cuckoo_hashing_visualization/">这里玩一玩</a></p>
</blockquote>
<h3 id="%E9%80%80%E7%BE%A4%E9%97%AE%E9%A2%98-%E5%B7%B2%E8%AF%BB%E6%9C%AA%E8%AF%BB%E6%B6%88%E6%81%AF%E8%AE%BE%E8%AE%A1-%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%E4%B8%8D%E8%83%BD%E5%88%A0%E9%99%A4%E5%B7%B2%E5%88%A0%E9%99%A4%E7%9A%84key%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86">退群问题, 已读未读消息设计? (布隆过滤器不能删除已删除的key,如何处理?)</h3>
<ul>
<li>已读未读只是一个0/1标记,直接使用bitmap来实现;每个用户附带一个bitmapId的字段,用来当bitmap的key;</li>
<li>退群问题:
<ol>
<li>退出群聊的成员只能标记删除，不能物理删除;退出的成员又重新加入,删除掉删除标记</li>
<li>再加个bitmap记录退群状态;</li>
</ol>
</li>
</ul>
<p>方案对比:</p>
<ul>
<li>一般的已读未读消息设计,对每个msg都保存两个列表,一个已读列表一个未读列表;此时一个用户id要占用4byte/8byte空间(int32 int64);</li>
<li>使用bitmap记录,只占2bit(key:1bit value: 1bit);</li>
</ul>
<h3 id="%E7%83%AD%E7%82%B9key%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88">热点key解决方案?</h3>
<blockquote>
<p>相同的key会请求到同一台数据分片上，导致该分片负载较高成为瓶颈问题，导致雪崩等一系列问题。</p>
</blockquote>
<p>问题:</p>
<ul>
<li>高访问量的Key，一个key访问的QPS超过1000就要高度关注了，比如热门商品，热门话题等。</li>
<li>大Value，有些key访问QPS虽然不高，但是由于value很大，造成网卡负载较大，网卡流量被打满，单台机器可能出现千兆 / 秒，IO 故障。</li>
<li>热点 Key + 大 Value 同时存在，服务器直接挂。</li>
</ul>
<p>导致:</p>
<ul>
<li>数据倾斜问题：大 Value 会导致集群不同节点数据分布不均匀，造成数据倾斜问题，大量读写比例非常高的请求都会落到同一个 redis server 上，该 redis 的负载就会严重升高，容易打挂。</li>
<li>QPS 倾斜：分片上的 QPS 不均。</li>
<li>大 Value 会导致 Redis 服务器缓冲区不足，造成 get 超时。</li>
<li>由于 Value 过大，导致机房网卡流量不足。</li>
<li>Redis 缓存失效导致数据库层被击穿的连锁反应。</li>
</ul>
<p>如何发现问题:</p>
<ul>
<li>提前获知: 根据业务，人肉统计 or 系统统计可能会成为热点的数据，如，促销活动商品，热门话题，节假日话题，纪念日活动等;</li>
<li>Redis客户端通过计数的方式统计key的请求次数; 代码入侵性较强;</li>
<li>代理层统计: 多做一层代理,统一cache查询入口,做收集上报; 这个成本比较高,需要自己开发;</li>
<li>服务端收集: 监控集群QPS, 对高QPS的节点使用<code>monitor</code>来分析热点key;(monitor会打印所有的命令) 在高并发条件下，会存在内存暴涨和 Redis 性能的隐患，所以此种方法适合在短时间内使用;</li>
<li>redis4.0有基于LFU的热点key发现机制;</li>
</ul>
<p>热点key解决办法:</p>
<ul>
<li>key拆分: 二级结构如hash,可以进行拆分;</li>
<li>迁移热点key: 热点key单独跑个节点;</li>
<li>限流, 对于写命令我们可以单独针对这个热点key来限流;</li>
<li>增加本地缓存: 对于数据一致性不是那么高的业务，可以将热点 key 缓存到业务机器的本地缓存中.但是当数据更新时，可能会造成业务和 Redis 数据不一致。</li>
</ul>
<h3 id="%E5%A4%A7value%E6%80%8E%E4%B9%88%E6%8B%86%E5%88%86">大Value怎么拆分？</h3>
<p>根据业务总结出value的大小:</p>
<ol>
<li>大：string类型 value &gt; 10K，set、list、hash、zset 等集合数据类型中的元素个数 &gt; 1000。</li>
<li>超大：string类型 value &gt; 100K，set、list、hash、zset 等集合数据类型中的元素个数 &gt; 10000。</li>
</ol>
<p>几个典型的分拆方案：</p>
<ol>
<li>
<p>一个较大的kv拆分成几个kv，将操作压力平摊到多个redis实例中，降低对单个redis的IO影响;</p>
</li>
<li>
<p>将分拆后的几个kv存储在一个hash中，每个field代表一个具体的属性，使用hget,hmget来获取部分的value，使用hset，hmset来更新部分属性;</p>
</li>
<li>
<p>hash、set、zset、list 中存储过多的元素: 类似于场景一种的第一个做法，可以将这些元素分拆;</p>
</li>
<li>
<p>固定一个桶的数量，比如10000，每次存取的时候，先在本地计算field的hash值，对10000取模，确定该field落在哪个key上，核心思想就是将value打散，每次只 get 你需要的;</p>
<pre class="hljs"><code><div>newHashKey = hashKey + (hash(field) % 10000); 
hset(newHashKey, field, value); 
hget(newHashKey, field)
</div></code></pre>
</li>
</ol>

</body>
</html>
