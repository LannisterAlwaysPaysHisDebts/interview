# 分布式/微服务基础问题
## 理论
### 谈一谈你对分布式系统/微服务架构的理解
大体思路”微服务本质是人员组织架构演进与关注点分离”

为了解决传统单体服务架构带来的各种问题，代码数量庞大，迭代测试维护困难，可能因为一处改动测试不到位造成整个服务瘫痪等问题，分布式系统就是将一个大的服务拆分成几十个甚至上百个微小的服务。如果把单体架构服务器比做篮子，那代码就是鸡蛋，不要让所有鸡蛋别装在一个篮子里，也方便大家分工开发，代码不在一个项目里，也不会冲突;

### 分布式系统环境下各自有什么优缺点？
优点:
- 系统可用性提升; 一般分布式都会做HA;
- 系统并发能力提升; 水平扩展
- 低延迟: 可以跨地域部署, 用户请求分发到离得比较近的服务器;

缺点:
- 严重依赖网络, 一个服务的网络出现问题, 整个请求都会出现问题;
- 增加运维成本;
- 一致性，可用性，分区容错性无法同时满足; (单机不存在一致性问题;)

### 高并发编程经验?
1. QPS、TPS多少才算高并发?
能达到系统线程最大值都算高并发;通常来说集群QPS都是W级到千万级,TPS要比QPS少好几个数量级;真实情况还得根据业务来分析;

让我们算一笔帐。某个产品，⽇活 2000 万，每个⽤户每天 500 个请求，那么每天就是 100 亿的访问量。你也可以当做日活 5000 万， 200 个请求，也是 100 亿。其实日活几千万的产品并不多，那些后台没事乱搞的 app 不算。每天按照十小时计算，这样系统的 QPS 是：每天100亿访问量 / 每天10⼩时 / 3600秒 = 27.78 万，就按照 30 万算吧。那么单机 QPS 就是 30 万除以服务器数。那么问题来了，对于日活好几千万的高大上系统，如果单机 QPS 达到 3 万，只需要 10 台机器，如果 QPS 是 3千，就需要 100 台机器。所以有的时候并没有我们想象中的那么高QPS;

2. 高并发常用的一些数据:
- QPS: 服务器每秒处理查询次数;
- TPS: 服务器每秒处理的事务数,单接口通常TPS=QPS,但是对一次完整的请求,涉及到了N多服务M多接口,但只算一次TPS;
- RT: 响应时间,分最大、最小、平均; 一般100ms以内正常,300ms可以接受,1s就很慢很慢了(参考游戏);
- 并发数: 同时请求的数量;
- 吞吐量: 每秒承受的用户访问量; 单个请求对系统资源的耗费,越多吞吐量越低;
- PV: 访问次数,刷新一次算一次PV;
- UV: 独立访客数,根据用户唯一标示去重;
- LOAD: 系统负荷,top有load average参数,0.7代表70%;

3. 经验
没经验就说没实操经验，但常见的优化方法和思路的了解吧，不然遇到问题两眼一摸黑，现查现学就太耽误事了

大厂的非相关核心组按照小厂对待，虽然流量很大但其实没啥技术含量都是固定套路。
我没有高并发项目经验，但是面试的时候经常被问到高并发、性能调优方面的问题，有什么办法可以解决吗？ - 知乎
https://www.zhihu.com/question/421237964

### 什么是DDD?讲讲你的理解;
DDD领域驱动设计, 根据业务对复杂软件系统进行拆解, 满足高内聚、低耦合的要求.
一般划分为四层: 
1. VO(view object):一个页面的数据整合;
2. DTO(data transfer object): 逻辑整合,传输数据;
3. DO(domain object): 对象的业务逻辑集合;
4. PO(persistent object): 数据库部分;

按照*我的理解*, 拿购物车举例,PO负责从数据库读数据或者从其他渠道获取数据;DO则是一个购物车类,里面有购物车的各种方法,例如清空购物车,添加商品;DTO则是完成一个业务逻辑,例如展示购物车,我需要调用购物车DO的方法拿到当前用户购物车的内容,我还可能需要获取其他内容,这些业务逻辑都集合在DTO里面,整理出一套数据传输给VO层; VO则是与前端交互的逻辑, 将DTO给的数据处理成给前端的数据.

再谈*我的理解*: 根据「领域」划分整个业务,这些领域是若干个DO层类,通过PO层获取数据,提供各种方法;业务逻辑在DTO完成,调用DO层的各种方法完成业务,再传给VO层展示.

备注: 高可用常用分层架构: 客户端、反向代理层、接入层、服务层、存储层;

### 讲讲CAP
- CAP是分布式系统能够满足的三种特性: Consistency一致性、Availability可用性、Partition tolerance分区容错性;
- 一致性表示所有节点在同一时间的数据完全一致,
- 可用性指服务一直可用，而且是正常响应时间(数据不一定最新);
- 容错性指在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务。
- 只能满足其中两点,例如出现网络故障,主从仍然可以访问,满足P;但是从库数据偏移;如果从库允许操作,就不满足一致性,如果从库不允许操作,就不满足可用性;
- 根据业务不同有不同的侧重,例如对用户服务通常牺牲一致性,满足AP,保证服务正常运行,只是数据可能有延迟;对库存或者交易订单通常牺牲可用性,必须保证数据一致.

### 讲讲你对service mesh的理解

### 微服务的几个痛点?
1. 服务注册与发现(CAP理论,一致性、可用性、分区容忍性(容忍通信失败));
2. rpc调用, grpc或者go自带的rpc功能;
3. 微服务网关;
4. 高可用: 熔断、限流、降级、无状态、幂等性;
5. 负载均衡;
6. 认证与授权: jwt;
7. 链路追踪;
8. 日志采集elk;
9. 监控预警;

### 谈一谈你对Serveless的理解. 你认为 Serveless 是未来吗? 为什么?
大体思路”Serveless 是继 docker 与容器编排之后的又一次应用开发与基础设施提供方之间的边界划分”
大体思路”是云服务的未来，把蛋糕从企业的IT、运维与中间件部门切走，形成规模效应，做得越多赚得越多；公司内的话 servless 能够帮助加速前台业务迭代，但对中后台的收益还看不到，未来可能会有比servless更适合中后台的架构”

### raft有什么特点?讲下raft算法的基本流程？raft算法里面如果出现脑裂怎么处理？
- raft协议中，一个节点任一时刻处于以下三个状态之一：leader、follower、candidate;如果收到majority的造成票（含自己的一票）则切换到leader状态；如果发现其他节点比自己更新，则主动切换到follower。

- 所有节点启动时都是follower状态；
- follower在timeout内没有收到来自leader的心跳, 增加节点本地的current term(当前学期)，切换到candidate状态, 投自己一票,并行给其他节点发送投票请求;
- 先来先得;
- 获得超过半数的投票,即设置自己是leader,并向其他节点发出通知;
- 如果没有投出leader,则继续投票; 为了防止长时间的平票,raft引入了随机超时时间,而且通常节点数量都是奇数个;
- raft所有更新请求会转发给leader,leader通过记录log的方式让follower与leader保持一致性;

脑裂:
- 老leader因为网络原因仍然认为自己是leader;此时客户端在新leader上更新了x,在老leader读取的是过期的值;
- 新的分区一定是多数派(这样才能选举出新leader),旧leader一定在少数派分区;
- 引入一个新的概念: region leader, 区域领导与leader不一定是同一个节点,所有读写请求都必须通过region leader转发给leader;

### 有没有了解过paxos和zookeeper的zab算法，与raft算法有啥区别？
zab算法大致流程与raft一样，只有在选举时不是遵循的先来先得规则，而是根据myid和偏移量来决定；

## rpc
### 说说你用过的RPC框架，假如让你实现RPC框架的序列化部分你会怎么做
前期协商: 
- client/server通过tcp建立连接(go net包);
- 定义好一个Option结构体,里面包含协商信息, 比如`MagicNumber`用于申明这是一个rpc请求,`CodecType`用于申明编码类型; 这个Option可以固定统一用json编码;
- client先发送Option,告诉server我要发送rpc数据了, 同时告诉server编码类型;server收到option,比对`MasgicNumber`,通过`CodecType`获取对应的编码器;

编码器: `go encoding包有很多编码,例如json, gob等等; 只要实现encode/decode功能就行了`;

数据交换流程:
- 数据定义两个结构体header与body; 其中header结构体用来保存这次请求的信息,例如`Service.Method`代表调用的服务与方法,`SeqId`来区分不同请求,`Error`字段保存错误;

### 公司使用什么 RPC 框架？，可以介绍一下 RPC 的工作原理吗？
<img src="https://img1.sycdn.imooc.com/5e12980400018cd315960916.png" width=200px>

rpc原理: 
1. 服务集成RPC后，服务（Provider）启动后会通过Register（注册）模块，把服务的唯一ID和IP地址，端口信息等注册到RPC框架注册中心（Registry）;
2. 当调用者（Consumer）想要调用服务的时候，通过 Provider 注册时的的服务唯一 ID 去注册中心查找在线可供调用的服务，返回一个 IP 列表（notify）;
3. 第三步 Consumer 根据一定的策略，比如随机 or 轮训从 Registry 返回的可用 IP 列表真正调用服务（invoke）。
4. 最后是统计功能，RPC 框架都提供监控功能，监控服务健康状况，控制服务线上扩展和上下线（count）

Provider：服务提供方，CS 模型中的 Server。
Consumer： 调用远程服务服务消费方，CS 模型中的 Client。
Registry：服务注册与发现的服务管理中心。
Monitor：统计服务的调用次数和调用时间的监控中心。
Container：服务运行容器

使用的是grpc与protobuf

### 你对 RPC 了解的很透彻，那你能否自己写一个 RPC 框架？可以简答描述下思路也行。
- 服务容器负责启动，加载，运行服务提供者。
- 服务提供者在启动时，向注册中心注册自己提供的服务，暴露自己的 IP 和端口信息。
- 服务消费者在启动时，向注册中心订阅自己所需的服务。
- 注册中心返回服务提供者列表给消费者，如果有变更，注册中心将基于长连接推送给数据消费者。
- 服务消费者，从提供这地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另外一台服务调用。
- 服务消费者和提供者，在内存中累计调用次数和调用时间，定时发送一次统计数据到监控中心。

### 已经有了RESTFUL,为什么要用rpc?
> 应该根据业务灵活站位

restful优点
- http场景是用于web架构，而不是分布式系统间通信; RESTFUL api通常是给浏览器、给前端调用,或者给外部开放api接口使用; 场景对延迟/速度要求没那么高;
- http开发简单, 可读性好, 测试也比较直接, 部署方便, 跨语言的支持;

缺点: 
- 有用信息占比少, 包含了大量的HTTP头等信息;
- 效率低, 还是因为第七层的缘故;

rpc: 
- rpc的场景是服务间的调用, 需要低延迟高效率; rpc可以走tcp层, 也可以走http层;
- rpc框架通常都封装了服务发现、负载均衡、熔断降级之类面相服务的高级特性

RPC 支持长链接，通信不必每次都要像 http 一样去重复 3 次握⼿，减少了网络开销。 RPC 框架一般都有注册中心模块，有完善的监控管理功能，服务注册发现、服务下线、服务动态扩展等都方便操作，服务化治理效率大大提高。基于 TCP 协议实现的 RPC，能更灵活地对协议字段进行定制，相比 http 能减少网络传输字节数，降低网络开销（握手）提高性能。实现更大的吞吐量和并发数，但是需要更多的关注底层复杂的细节， 对开发人员的要求也高，增加开发成本。
